{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import io\n",
    "from scipy.stats import mode\n",
    "from heapq import nsmallest\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global vars used throughout file\n",
    "dct = io.loadmat('./hw1data.mat')\n",
    "X = dct['X'].astype(int) # see piazza @35\n",
    "Y = dct['Y'].astype(int)\n",
    "N, K, D = 10000, 10, 784\n",
    "STEP_SIZE = 1e-6\n",
    "MAX_ITER = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# norm, eval_f, and plot_run are same for (ii) and (iv)\n",
    "\n",
    "def norm(v):\n",
    "    return sum(np.dot(v,v))\n",
    "\n",
    "\n",
    "def eval_f(theta):\n",
    "    \"\"\" evaluates f at theta\"\"\"\n",
    "    result = 0\n",
    "    \n",
    "    for i in range(N):\n",
    "        label = Y[i]\n",
    "        vec = X[i] - theta[label] # vectorizing sum, numpy broadcasting\n",
    "        result += -0.5 * np.dot(vec, vec)\n",
    "        \n",
    "    return result\n",
    "\n",
    "def plot_run(f_vals, step_size):\n",
    "    plt.figure()\n",
    "    plt.plot(range(iterations),f_values,'ro')\n",
    "    plt.title('step size ' + str(step_size))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (ii) function definitions\n",
    "def grad_of_f(theta):\n",
    "    \"\"\"returns gradient of f valued at theta\"\"\"\n",
    "    grad = np.zeros(10)\n",
    "    for i in range(N):\n",
    "        label = Y[i]\n",
    "        grad[label] += sum(X[i] - theta[label]) # numpy broadcasting\n",
    "    \n",
    "    return grad\n",
    "\n",
    "def optimize_theta(theta, step_size, max_iter):\n",
    "    \"\"\"iterative optimization algorithm from 4(ii)\n",
    "    \n",
    "    returns array of function value from iterations\n",
    "    \"\"\"\n",
    "    f_vals = [eval_f(theta)] # starting f value\n",
    "    i = 0\n",
    "    \n",
    "    while i < max_iter:\n",
    "        grad = grad_of_f(theta)\n",
    "        if (norm(grad) < 1e-8): # if optimal value reached\n",
    "            break\n",
    "        theta -= step_size * grad # else descend theta\n",
    "        f_vals.append(eval_f(theta))\n",
    "        i += 1\n",
    "    \n",
    "    return f_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-0cf190555296>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# (ii) run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mf_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimize_theta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTEP_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_ITER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplot_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTEP_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-cdc55435b4a0>\u001b[0m in \u001b[0;36moptimize_theta\u001b[0;34m(theta, step_size, max_iter)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_of_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1e-8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# if optimal value reached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mtheta\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mstep_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;31m# else descend theta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-2448453ed5eb>\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not iterable"
     ]
    }
   ],
   "source": [
    "# (ii) run\n",
    "theta = np.zeros(K)\n",
    "f_vals = optimize_theta(theta, STEP_SIZE, MAX_ITER)\n",
    "plot_run(f_vals, STEP_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (iv), (v) function definitions\n",
    "\n",
    "def fast_grad_of_f(theta, sample):\n",
    "    \"\"\"returns approximate fast gradient of f using single sample x\"\"\"\n",
    "    x, label = sample[:-1], sample[-1]\n",
    "    grad = np.zeros(10)\n",
    "    grad[label] += N * sum(x - theta[label]) # scale grad by N\n",
    "    return grad\n",
    "\n",
    "def draw_hist(theta, X_Y):\n",
    "    \"\"\"draws histogram as specified in (v)\"\"\"\n",
    "    fast_grads = [fast_grad_of_f(theta, X_Y[i]) for i in range(N)]\n",
    "    grad = grad_of_f(theta)\n",
    "    \n",
    "    \n",
    "\n",
    "def fast_optimize_theta(theta, step_size, max_iter):\n",
    "    \"\"\"iterative optimization algorithm from 4(iv)\n",
    "    \n",
    "    returns array of function value from iterations\n",
    "    \"\"\"\n",
    "    f_vals = [eval_f(theta)] # starting f value\n",
    "    X_Y = np.concatenate((X, Y), axis=1) # concat for permuting data\n",
    "    i, histogram_step = 0, random.randrange(max_iter) # arbitrary step to draw histogram \n",
    "    \n",
    "    while i < max_iter:\n",
    "        np.random.permutation(X_Y) # permute again if dataset exhausted\n",
    "            \n",
    "        for j in range(N):\n",
    "            # do (v) at arbitrary step\n",
    "            if i == histogram_step:\n",
    "                draw_hist(theta)\n",
    "                \n",
    "            grad = fast_grad_of_f(theta, sample=X_Y[j])\n",
    "            if (norm(grad) < 1e-8): # if optimal value reached\n",
    "                return f_vals\n",
    "            theta -= step_size * grad # else descend theta\n",
    "            f_vals.append(eval_f(theta))\n",
    "            i += 1\n",
    "    \n",
    "    return f_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (v), (vi) run\n",
    "theta = np.zeros(K)\n",
    "fast_f_vals = fast_optimize_theta(theta, STEP_SIZE, MAX_ITER)\n",
    "plot_run(fast_f_vals, STEP_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#################### Rui's #######################\n",
    "Matrix = io.loadmat('./hw1data.mat')\n",
    "X_Y = np.concatenate((Matrix['X'],Matrix['Y']),axis=1)\n",
    "# print(X_Y.shape)\n",
    "n = len(X_Y) # 10000\n",
    "d = 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = np.zeros(10)\n",
    "sum_element = np.zeros(10)\n",
    "sum_sq_element = np.zeros(10)\n",
    "# print(count, sum_element, sum_sq_element)\n",
    "\n",
    "for data in X_Y:\n",
    "    # inc count[label]\n",
    "    i = int(data[d])\n",
    "    count[i]+=1 \n",
    "    for j in range(784):\n",
    "        sum_element[i]+=data[j]\n",
    "        sum_sq_element[i]+=data[j]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Iterations:50000\n",
      "Minimum of f appears at theta=[ 44.27924043  19.75893899  37.44431081  35.87573814  30.72689478\n",
      "  31.51604632  34.50088699  28.97490797  37.49111282  31.21297206]\n",
      "First derivative at minimum point: [-754912.69148861 -209821.75395381 -693803.98572783 -489572.3669293\n",
      " -530145.2850626  -664811.39825932 -534461.03501291 -421343.64695031\n",
      " -646851.45811004 -482076.17523907]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEDCAYAAADOc0QpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEwMpZVGdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b05b898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print sum_element, count\n",
    "def norm_f(v):\n",
    "    return sum(v*v)\n",
    "def eval_f(theta):\n",
    "    f = 0\n",
    "    f+=sum(sum_sq_element) - 2*sum(sum_element*theta) + 784*sum(count*theta**2)\n",
    "    f = f*0.5\n",
    "    return f\n",
    "theta = np.zeros(10)\n",
    "delta_f = 784*theta*count-sum_element\n",
    "f_values = []\n",
    "iterations=0\n",
    "it_max = 50000\n",
    "while (norm_f(delta_f)>=1e-16) and (iterations<it_max) :\n",
    "        n = 0.0000000001\n",
    "        theta = theta - n*delta_f\n",
    "        delta_f = 784*theta*count-sum_element\n",
    "        f = eval_f(theta)\n",
    "        f_values.append(f)\n",
    "        #print delta_f\n",
    "        iterations+=1\n",
    "\n",
    "print('# Iterations:' + str(iterations))\n",
    "print('Minimum of f appears at theta='+str(theta))\n",
    "print('First derivative at minimum point: '+str(delta_f))\n",
    "plt.plot(range(iterations),f_values,'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
